{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "biometrics task-model 1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarinAmir/Smile-analysis_model/blob/main/biometrics_task_model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "859b3fca-6468-4005-cc8a-28784a0211a2"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "bb7b7d84-26a4-4acd-bec0-2ee8734a7e83"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.6923660919999293\n",
            "GPU (s):\n",
            "0.04877669199981938\n",
            "GPU speedup over CPU: 75x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5jo62l12cCF",
        "outputId": "5a0acce0-04d9-4410-e230-0cacf3099b34"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/moheb432/principles-of-smile.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "'biometrics_dataset - Sheet1.csv'   test.csv\n",
            " cloned-repo\t\t\t    train.csv\n",
            " cropped_teeth\t\t\t    Untitled.ipynb\n",
            " dataset.csv\t\t\t    valid.csv\n",
            " dataset_split.ipynb\t\t    vgg.ipynb\n",
            " mobile-net.ipynb\t\t    weight_converting.ipynb\n",
            " README.md\t\t\t    weights.hkl\n",
            "'teeth_not cropped'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXWM5UHNtNEf"
      },
      "source": [
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-J5xT9vtMye"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6k3U7qTtPYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33a75e7-821d-45c5-f7b9-977d313e838c"
      },
      "source": [
        "def append_ext(fn):\n",
        "    return fn+\".jpg\"\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df[\"img\"] = df[\"img\"].apply(append_ext)\n",
        "df = df.replace(np.nan, 0)\n",
        "\n",
        "columns = ['gummy', 'golden_proportion ', 'gap', 'crowding',\n",
        "       'incisal embrassure ', 'color', 'Central line', 'gum tissue health',\n",
        "       'Crooked', 'Central Incisor W/H Ratio', 'Black triangle', 'perfect']\n",
        "df=df.sample(frac=1).reset_index(drop=True)\n",
        "df.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['img', 'gummy', 'golden_proportion ', 'gap', 'crowding',\n",
              "       'incisal embrassure ', 'color', 'Central line', 'gum tissue health',\n",
              "       'Crooked', 'Central Incisor W/H Ratio', 'Black triangle', 'perfect',\n",
              "       'labels'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDsFHQoDtZuY",
        "outputId": "0e289372-a83d-4218-e461-ded09fa8f64d"
      },
      "source": [
        "\n",
        "train_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_data_generation.flow_from_dataframe(dataframe=df[:155],\n",
        "                                                         directory=\"./cropped_teeth\",\n",
        "                                                         x_col=\"img\",\n",
        "                                                         y_col=columns,\n",
        "                                                         target_size=(224,224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode=\"raw\",seed=3)\n",
        "# preprocessing the testing set\n",
        "valid_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_set = valid_data_generation.flow_from_dataframe(dataframe=df[155:175],\n",
        "                                                         directory=\"./cropped_teeth\",\n",
        "                                                         x_col=\"img\",\n",
        "                                                         y_col=columns,\n",
        "                                                         target_size=(224,224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode=\"raw\",seed=3)\n",
        "\n",
        "# preprocessing the testing set\n",
        "test_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_data_generation.flow_from_dataframe(dataframe=df[175:],\n",
        "                                                         directory=\"./cropped_teeth\",\n",
        "                                                         x_col=\"img\",\n",
        "                                                         y_col=None,\n",
        "                                                         target_size=(224,224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode=None,seed=0)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 155 validated image filenames.\n",
            "Found 20 validated image filenames.\n",
            "Found 19 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4J-fna85ibv"
      },
      "source": [
        "# **VGG16:**\n",
        "![Build Status](https://images4.arabicprogrammer.com/948/02/02b6266c608492d1007bbb560e762ab4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_mXgLP22VIp",
        "outputId": "5c5d20c9-c49a-4304-8df1-b444bd417c58"
      },
      "source": [
        "\n",
        "def vgg():\n",
        "  \n",
        "  input = Input([224,224,3])\n",
        "  \n",
        "  x = Conv2D(64,3, activation='relu')(input)\n",
        "  x = Conv2D(64, 64, activation='relu')(x)\n",
        " \n",
        "  x = MaxPool2D(2, strides=2)(x)\n",
        "  \n",
        "  x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(128,3, padding='same', activation='relu')(x)\n",
        "  x = MaxPool2D(2, strides=2, padding='same')(x)\n",
        "  \n",
        "  x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(256, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(256, 3, padding='same', activation='relu')(x)\n",
        "  x = MaxPool2D(2, strides=2, padding='same')(x)\n",
        "  \n",
        "  x = Conv2D(256,3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "  x = MaxPool2D(2, strides=2, padding='same')(x)\n",
        "  \n",
        "  x = Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "  x = Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "  x = MaxPool2D(2, strides=2, padding='same')(x)\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(4096, activation='relu')(x)\n",
        "  x = Dense(4096, activation='relu')(x)\n",
        "  \n",
        "  output = Dense(12, activation='softmax')(x)\n",
        "  model = Model(input, output)\n",
        "  \n",
        "  return model\n",
        "\n",
        "model=vgg()\n",
        "model.summary()\n",
        "E_S= EarlyStopping(monitor='val_binary_accuracy',\n",
        "                   patience=6\n",
        "                   ,mode='max'\n",
        "                   , restore_best_weights=True\n",
        "                   )\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss = 'BinaryCrossentropy',\n",
        "              metrics = ['BinaryAccuracy'])\n",
        "history=model.fit(x=training_set, \n",
        "                  validation_data=valid_set, \n",
        "                  epochs=50,\n",
        "                  callbacks=[E_S])\n",
        "\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 222, 222, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 159, 159, 64)      16777280  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 79, 79, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 79, 79, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 79, 79, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 40, 40, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 40, 40, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 40, 40, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 40, 40, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 20, 20, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 20, 20, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 10, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 10, 10, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 5, 5, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              52432896  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                49164     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,395,532\n",
            "Trainable params: 98,395,532\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1282s 188s/step - loss: 2.4959 - binary_accuracy: 0.7495 - val_loss: 0.6383 - val_binary_accuracy: 0.7333\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 152s 30s/step - loss: 0.6642 - binary_accuracy: 0.7376 - val_loss: 0.6164 - val_binary_accuracy: 0.7333\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 152s 30s/step - loss: 0.6077 - binary_accuracy: 0.7478 - val_loss: 0.6024 - val_binary_accuracy: 0.7333\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 152s 30s/step - loss: 0.5668 - binary_accuracy: 0.7376 - val_loss: 0.5091 - val_binary_accuracy: 0.7333\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 152s 30s/step - loss: 0.5030 - binary_accuracy: 0.7376 - val_loss: 0.4816 - val_binary_accuracy: 0.7333\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 152s 30s/step - loss: 0.4977 - binary_accuracy: 0.7387 - val_loss: 0.4650 - val_binary_accuracy: 0.7333\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 152s 31s/step - loss: 0.4798 - binary_accuracy: 0.7376 - val_loss: 0.4734 - val_binary_accuracy: 0.7333\n",
            "Epoch 8/50\n",
            "4/5 [=======================>......] - ETA: 29s - loss: 0.4763 - binary_accuracy: 0.7412"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVUHKsfIqSKv"
      },
      "source": [
        "model.load_model(\"model.h5\")\n",
        "predictions= model.predict(test_set)\n",
        "y=[]\n",
        "print(\"10 Sample predictions:\")\n",
        "for pred in predictions:\n",
        "\n",
        "  pred[pred>0.6]=1\n",
        "  pred[pred<=0.6]=0\n",
        "pd.DataFrame(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm29oKb45CA8"
      },
      "source": [
        "\n",
        "model.save(\"my_h5_model.h5\")\n",
        "\n",
        "history.history\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mib359pqUhr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}